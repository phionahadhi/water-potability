# -*- coding: utf-8 -*-
"""water quality.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1gpnmZnxYhAgiSss_psV88VDoed5BE2-x

*Water portability*
*Potable water, is water that is safe for oral consumption , either when drunk directly in liquid form or consumed indirectly through food preparation.

*Portable water is free from harmful comtaminants and bacteria, therefore safe for drinking and food preparation

*Most water is more oftenly supplied through taps, which is refered to as tap water.In developing countries most water are fetched from rivers and lakes.

*Even though just a small fraction of water is used for direct or indirect consumption such as drinking water and food preparation .

*water portability is also important to water used in irrigation during planting seasons which be associated with risks.

*water portability test is a crucial evaluation of the quality of water which determines it's safety for human consumption.
"""

import numpy as np
import  pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import warnings
warnings.filterwarnings ('ignore')

"""dataset: https://www.kaggle.com/adityakadiwal/..."""

df = pd.read_csv('/content/drive/MyDrive/archive (9)/water_potability.csv')  #loading the dataset
df.head()

"""*The dataset contains input elements of water that will be used to determine its safety for consumption (independent variables),
portability column is the dependent variable*
"""

df.columns #list of columns

"""1.ph:pH is the acidity or the alkality of water.

2.Hardness:The amount of dissolved calcium and magnesium in the water.

3.Solids: is the total amount of solids dissolved in the water, including soluble hydrogen carbonate ions, chloride salts, sulphates, calcium, magnesium, sodium, potassium, volatile solids and non-volatile solids.

4.chloramines:The amount of clorine and amonia that is contained is water.

5.Sulphate: The levels of Sulphate in water.

6.Conductivity: Electrical conductivity of water in  Âµmhos/cm.

7.Organic_carbon: measures organic compounds in a water sample.

8.Trihalomethanes: Amount of Trihalomethanes in water. Trihalomethanesis a byproduct of water treatement process.

9.Turbidity:the cloudiness or haziness of water caused by large numbers of individual particles that are generally invisible to the naked eye.

10.The safety of water for human,animal consumption and plant irrigation.
"""

df['Potability'].unique() #finding unique values in the potability columns

"""*in the potability column, 0 means the water is not potable, 1 the water is potable*

#Data Cleaning#
"""

df.shape #rows,columns

df.dtypes #data type of each and every column in the dataset

df.info() #short summary of the data in the dataset

"""*df.info indicated that there are some missing values from some columns, so we're going to find out which columns have missing values and by how many.*"""

df.isnull().sum() #total number of null values in the data

"""checking what percentage of the missing values are there per column."""

df_NaN= df.isnull().sum().reset_index()
df_NaN.columns = ['Column','Null_count']
df_NaN['%miss_value'] = round(df_NaN['Null_count']/len(df),2)*100
df_NaN

"""considering the high percentages of null values per columns, we won't drop the null values since our dataset is small and by dropping the rows with missing values might affect the model ,so we will sort for different technicques to fill the missing values."""

df.describe()

"""visualizing the distribution of data in the values columns to check if they are normally distributed.

*ph histogram*
"""

df['ph'].plot(kind = 'hist')
plt.show()

"""*sulfate histogram*"""

df['Sulfate'].plot(kind = 'hist')
plt.show()

"""*Trihalomethanes histogram*"""

df['Trihalomethanes'].plot(kind = 'hist')
plt.show()

"""from the visualization, the data seem to be close to being normally distributed so i can replace the missing values with mean values."""

df = df.fillna(df.mean(),)
df.head()
#filling the missing values columns with the mean of every columns,pH will be filled with 7.08.. , Sulphate = 333.77.. ,Trihalomethanes= 66.396..

# rechecking if the missing spaces are filled
df.isnull().sum()

"""#Exploratory Data Analysis#

*checking if we need to do column reduction or dimensionality reduction, through correlation.*
"""

corr_matrix = df.corr() #applying correlation
corr_matrix

#visualizing the data using heatmaps,for easier readability
sns.heatmap(df.corr(),annot=True)
fig= plt.gcf()
fig.set_size_inches(10,7)
plt.show()

"""from the heatmap visualization there are no columns which are highly correlated.that is if two columns have more than 0.5-0.6 correlation that means we'll have to drop one column since the model can do well without one column without loosing too much information."""

df_hist_plot = df.hist(figsize=(20,20), color = '#5F9EA0')

"""*most of the colums seem to have normal dist...although there are a few like 'solids', that are left-skewed*"""

for col in df.columns:
  sns.histplot(data=df, x=col, kde=True, hue='Potability')
  plt.show()

df.groupby('Potability').mean().T #more analysis using mean

"""#checking for outliers in each columns using boxplot"""

for col in df.columns:
  sns.boxplot(data=df, x=col)
  plt.show()

"""*from the visualization, almost all the columns have outliers.we're going to keep the outliers since myb the outliers are the 'not potable' water, hence the outliers are important to the data to maintain balance between potable and none portable data.*"""

df['Potability'].value_counts() #checking the distribution of the potability column

"""*this shows the data is slightly imbalanced*

#Data Preprocessing#
"""

X= df.drop('Potability', axis= 1)   #dividing the columns into dependent and independent variambles
y=df['Potability']

X.head()  #columns of the independent variables

y.head() #the dependent variable

"""#Feature scaling#"""

from sklearn.preprocessing import MinMaxScaler  #using MinMaxScaler since the standard scaler generates negative values in the dataset
scaler= MinMaxScaler()

X_scaled = scaler.fit_transform(X)
X_scaled #rescaling the X columns into the range of 0-1

print("Number of negative values in the dataset:", np.sum(X_scaled < 0))  #checking for negative values in the dataset after rescaling

"""#Train test data split#"""

from sklearn.model_selection import train_test_split
X_train,X_test,y_train,y_test=train_test_split (X_scaled,y, test_size=0.3, random_state=20, stratify=y )

X_train.shape, X_test.shape

X_train

"""#Model Training and Evaluation:#

1. LogisticRegretion
2. DecisionTreeClassifier
3. RandomForestClassifier
4. Support Vector Classifier
5. Naive-Bayes, MultinomialNB,GaussianNB
6. GradientBoostingClassifier

*Importing Models*
"""

from sklearn.linear_model import LogisticRegression
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier,GradientBoostingClassifier
from sklearn.svm import SVC
from sklearn.naive_bayes import MultinomialNB,GaussianNB
from sklearn.model_selection import GridSearchCV

#define models and parameters
model_params = {
    'svm': {
        'model':SVC(gamma='auto'),
        'params': {
            'C': [1, 10, 20,30,50],
            'kernel': ['rbf', 'linear']
        }
    },
    'random_forest': {
        'model': RandomForestClassifier(),
        'params': {
            'n_estimators': [60,70,80,100,200,300,400,500,600,700]
        }
    },
    'logistic_regression': {
        'model': LogisticRegression(solver='liblinear'),
        'params': {
            'C': [1, 5, 10,15,20,25,30]
        }
    },
    'naive_bayes_multinomial': {
        'model': MultinomialNB(),
        'params': {}
    },
    'naive_bayes_gaussian': {
        'model': GaussianNB(),
        'params': {}
    },
    'decision_tree': {
        'model': DecisionTreeClassifier(),
        'params': {
            'criterion': ['gini', 'entropy']
        }
    },
    'gradient_boosting': {
        'model': GradientBoostingClassifier(),
        'params': {
            'n_estimators': [60,70,80,100,200,300,400,500,600,700],
            'learning_rate': [0.01, 0.1, 0.5]
        }
    }
}

scores = []

for model_name, mp in model_params.items():
    try:
        clf = GridSearchCV(mp['model'], mp['params'], cv=5, return_train_score=False, error_score='raise')
        clf.fit(X_train, y_train)
        scores.append({
            'model': model_name,
            'best_score': clf.best_score_,
            'best_params': clf.best_params_
        })
    except Exception as e:
        print(f"Error with model {model_name}: {e}")

# Convert scores to a DataFrame for better readability
if scores:
    scores_df = pd.DataFrame(scores,columns=['model','best_score','best_params'])
    scores_df.sort_values(by=['best_score'], ascending=False)
    display(scores_df.style.background_gradient(cmap='viridis', subset=['best_score']))
else:
    print("No models successfully fitted.")

"""*the above data shows that random forest is the best ,followed by gradient_boosting and naive_baiyes_gaussian.*

Build confusion matric and classification report for the 1st 3 models
"""

#True Positive Rate(recall)=Represents the proportion of actual positives correctly identified by the model

from sklearn.metrics import accuracy_score, classification_report, confusion_matrix

RF= RandomForestClassifier(n_estimators=500)
RF.fit(X_train, y_train)
y_pred_rf= RF.predict(X_test)

# Evaluate the model
print("Accuracy:", accuracy_score(y_test, y_pred_rf))
print("Classification Report:\n", classification_report(y_test, y_pred_rf))
print("Confusion Matrix:\n", confusion_matrix(y_test, y_pred_rf))

"""*in the random forest model,accuracy of 68%,precision is good for both 1,0 ,recall and f1-score are imbalanced*"""

Grad_B= GradientBoostingClassifier(n_estimators=80, learning_rate=0.1)
Grad_B.fit(X_train, y_train)
y_pred_gb= Grad_B.predict(X_test)

# Evaluate the model
print("Accuracy:", accuracy_score(y_test, y_pred_gb))
print("Classification Report:\n", classification_report(y_test, y_pred_gb))
print("Confusion Matrix:\n", confusion_matrix(y_test, y_pred_gb))

"""*gradient boosting has an accuracy of 66%, similarly the precision matrix are similar,but the recall and f1-scores are imbalanced*"""

GaNB = GaussianNB()
GaNB.fit(X_train, y_train)
y_pred_gb = GaNB.predict(X_test)

# Evaluate the model
print("Accuracy:", accuracy_score(y_test, y_pred_gb))
print("Classification Report:\n", classification_report(y_test, y_pred_gb))
print("Confusion Matrix:\n", confusion_matrix(y_test, y_pred_gb))

"""*the bayes_gaussian model has an accuracy of 63%,the precision has droped , similarly the recal and f1-score does not look good at all*

Using ANN
"""

import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers

model=keras.Sequential()
model.add(layers.Dense(20, activation='relu', input_dim=9))
model.add(layers.Dense(10, activation='relu'))
model.add(layers.Dense(5, activation='relu'))
model.add(layers.Dense(10, activation='relu'))
model.add(layers.Dense(1,activation='sigmoid'))

model.compile(optimizer='adam',
              loss='binary_crossentropy',
              metrics=['accuracy'])
model.fit(X_train,y_train,epochs=900)

model.evaluate(X_test,y_test)

y_predicted= model.predict(X_test)
y_predicted[:10]

y_pred=[]
for element in y_predicted:
  if element >0.5:
    y_pred.append(1)
  else:
      y_pred.append(0)

y_pred[:10]

print(classification_report(y_test,y_pred))

"""*the ANN accuracy is 67%,the precision,recall and f1-score are better than random forest results.*

confusion matrix
"""

import seaborn as sn
cm = tf.math.confusion_matrix(labels= y_test,predictions= y_pred)

plt.figure(figsize = (10,7))
sn.heatmap(cm,annot=True,fmt='d')
plt.xlabel('predicted')
plt.ylabel('True Values')

from sklearn.metrics import roc_curve,auc

y_scores_rf = RF.predict_proba(X_test)[:, 1]
fpr,tpr,thresholds = roc_curve(y_test,y_scores_rf)
roc_auc = auc(fpr,tpr)

plt.figure(figsize=(7, 5))
plt.plot(fpr, tpr, color='blue',lw=2, label=f'ROC curve (area = {roc_auc})')
plt.plot([0,1],[0,1], color='red',lw=2, linestyle='--')
plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.05])
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('Receiver Operating Characteristic (ROC)')
plt.legend(loc='lower right')
plt.show()

y_scores_grad = Grad_B.predict_proba(X_test)[:, 1]
fpr,tpr,thresholds = roc_curve(y_test,y_scores_grad)
roc_auc = auc(fpr,tpr)

plt.figure(figsize=(7, 5))
plt.plot(fpr, tpr, color='blue',lw=2, label=f'ROC curve (area = {roc_auc})')
plt.plot([0,1],[0,1], color='red',lw=2, linestyle='--')
plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.05])
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('Receiver Operating Characteristic (ROC)')
plt.legend(loc='lower right')
plt.show()

y_scores_gaNB = GaNB.predict_proba(X_test)[:, 1]
fpr,tpr,thresholds = roc_curve(y_test,y_scores_gaNB)
roc_auc = auc(fpr,tpr)

plt.figure(figsize=(7, 5))
plt.plot(fpr, tpr, color='blue',lw=2, label=f'ROC curve (area = {roc_auc})')
plt.plot([0,1],[0,1], color='red',lw=2, linestyle='--')
plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.05])
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('Receiver Operating Characteristic (ROC)')
plt.legend(loc='lower right')
plt.show()

from sklearn.metrics import roc_curve, roc_auc_score

#ANN
fpr, tpr, thresholds = roc_curve(y_test, y_predicted)
roc_auc = roc_auc_score(y_test, y_predicted)

# Plot ROC curve
plt.figure()
plt.plot(fpr, tpr, color='darkorange', lw=2, label='ROC curve (area = %0.2f)' % roc_auc)
plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')
plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.05])
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('Receiver Operating Characteristic (ROC)')
plt.legend(loc="lower right")
plt.show()

"""from the above roc curves ANN model is the best model.

##Hyper parameter tuning##
"""

from sklearn.model_selection import StratifiedShuffleSplit
sss = StratifiedShuffleSplit(n_splits=1, test_size=0.3, random_state=42)

X= df.drop('Potability', axis= 1)   #dividing the columns into dependent and independent variambles
y=df['Potability']

X_scaled = scaler.fit_transform(X)
X_scaled

X_scaled_df = pd.DataFrame(X_scaled, columns=X.columns)

#splitting the data
for train_index, test_index in sss.split(X_scaled_df, y):
    X_train, X_test = X_scaled_df.iloc[train_index], X_scaled_df.iloc[test_index]
    y_train, y_test = y.iloc[train_index], y.iloc[test_index]

X_train.shape, X_test.shape

"""#Handling imbalanced data with SMOTE"""

from imblearn.over_sampling import SMOTE #import SMOTE

smote = SMOTE(random_state=42) #applying SMOTE to training data
X_train_smote, y_train_smote = smote.fit_resample(X_train, y_train)

y_train_smote.value_counts()

from sklearn.model_selection import RandomizedSearchCV
from sklearn.model_selection import StratifiedKFold

"""*model training and evaluation*"""

model_params = {
    'svm': {
        'model': SVC(gamma='auto'),
        'params': {
            'C': [1, 10, 20,30,50],
            'kernel': ['rbf', 'linear', 'poly']
        }
    },
    'random_forest': {
        'model': RandomForestClassifier(),
        'params': {
            'n_estimators': [60,70,80,100,200,300,400,500,600,700]
        }
    },
    'logistic_regression': {
        'model': LogisticRegression(solver='liblinear', multi_class='auto'),
        'params': {
            'C': [1, 5, 10,15,20,25,30]
        }
    },
    'naive_bayes_multinomial': {
        'model': MultinomialNB(),
        'params': {}
    },
    'naive_bayes_gaussian': {
        'model': GaussianNB(),
        'params': {}
    },
    'decision_tree': {
        'model': DecisionTreeClassifier(),
        'params': {
            'criterion': ['gini', 'entropy']
        }
    },
    'gradient_boosting': {
        'model': GradientBoostingClassifier(),
        'params': {
            'n_estimators': [60, 70,80,100,200,300,400,500,600,700],
            'learning_rate': [0.01, 0.1, 0.5],
        }
    }
}

scores = []

for model_name, mp in model_params.items():
    try:
        clf = GridSearchCV(mp['model'], mp['params'], cv=5, return_train_score=False, error_score='raise')
        clf.fit(X_train_smote, y_train_smote)
        scores.append({
            'model': model_name,
            'best_score': clf.best_score_,
            'best_params': clf.best_params_
        })
    except Exception as e:
        print(f"Error with model {model_name}: {e}")

# Convert scores to a DataFrame for better readability
if scores:
    scores_df = pd.DataFrame(scores,columns=['model','best_score','best_params'])
    scores_df.sort_values(by=['best_score'], ascending=False)
    display(scores_df.style.background_gradient(cmap='viridis', subset=['best_score']))
else:
    print("No models successfully fitted.")

"""*the accuracy of random forest has improved after balancing the dataset*

classification report,confusion matrix
"""

RF= RandomForestClassifier(n_estimators=500)
RF.fit(X_train_smote, y_train_smote)
y_pred_rf= RF.predict(X_test)

# Evaluate the model
print("Accuracy:", accuracy_score(y_test, y_pred_rf))
print("Classification Report:\n", classification_report(y_test, y_pred_rf))
print("Confusion Matrix:\n", confusion_matrix(y_test, y_pred_rf))

Grad_B= GradientBoostingClassifier(n_estimators=600, learning_rate=0.1)
Grad_B.fit(X_train_smote, y_train_smote)
y_pred_gb= Grad_B.predict(X_test)

# Evaluate the model
print("Accuracy:", accuracy_score(y_test, y_pred_gb))
print("Classification Report:\n", classification_report(y_test, y_pred_gb))
print("Confusion Matrix:\n", confusion_matrix(y_test, y_pred_gb))

GaNB = GaussianNB()
GaNB.fit(X_train_smote, y_train_smote)
y_pred_gb = GaNB.predict(X_test)

# Evaluate the model
print("Accuracy:", accuracy_score(y_test, y_pred_gb))
print("Classification Report:\n", classification_report(y_test, y_pred_gb))
print("Confusion Matrix:\n", confusion_matrix(y_test, y_pred_gb))

"""ANN"""

model2=keras.Sequential()
model2.add(layers.Dense(20, activation='relu', input_dim=9))
model2.add(layers.Dense(10, activation='relu'))
model2.add(layers.Dense(5, activation='relu'))
model2.add(layers.Dense(10, activation='relu'))
model2.add(layers.Dense(1,activation='sigmoid'))

model2.compile(optimizer='adam',
              loss='binary_crossentropy',
              metrics=['accuracy'])
model2.fit(X_train_smote,y_train_smote,epochs=900)

model2.evaluate(X_test,y_test)

y_predicted2= model2.predict(X_test)
y_predicted2[:10]

y_pred2=[]
for element in y_predicted2:
  if element >0.5:
    y_pred2.append(1)
  else:
      y_pred2.append(0)

"""ROC curve"""

y_scores_rf = RF.predict_proba(X_test)[:, 1]
fpr,tpr,thresholds = roc_curve(y_test,y_scores_rf)
roc_auc = auc(fpr,tpr)

plt.figure(figsize=(7, 5))
plt.plot(fpr, tpr, color='blue',lw=2, label=f'ROC curve (area = {roc_auc})')
plt.plot([0,1],[0,1], color='red',lw=2, linestyle='--')
plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.05])
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('Receiver Operating Characteristic (ROC)')
plt.legend(loc='lower right')
plt.show()

y_scores_grad = Grad_B.predict_proba(X_test)[:, 1]
fpr,tpr,thresholds = roc_curve(y_test,y_scores_grad)
roc_auc = auc(fpr,tpr)

plt.figure(figsize=(7, 5))
plt.plot(fpr, tpr, color='blue',lw=2, label=f'ROC curve (area = {roc_auc})')
plt.plot([0,1],[0,1], color='red',lw=2, linestyle='--')
plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.05])
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('Receiver Operating Characteristic (ROC)')
plt.legend(loc='lower right')
plt.show()

y_scores_gaNB = GaNB.predict_proba(X_test)[:, 1]
fpr,tpr,thresholds = roc_curve(y_test,y_scores_gaNB)
roc_auc = auc(fpr,tpr)

plt.figure(figsize=(7, 5))
plt.plot(fpr, tpr, color='blue',lw=2, label=f'ROC curve (area = {roc_auc})')
plt.plot([0,1],[0,1], color='red',lw=2, linestyle='--')
plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.05])
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('Receiver Operating Characteristic (ROC)')
plt.legend(loc='lower right')
plt.show()

#ANN
fpr, tpr, thresholds = roc_curve(y_test, y_predicted2)
roc_auc = roc_auc_score(y_test, y_predicted2)

plt.figure()
plt.plot(fpr, tpr, color='darkorange', lw=2, label='ROC curve (area = %0.2f)' % roc_auc)
plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')
plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.05])
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('Receiver Operating Characteristic (ROC)')
plt.legend(loc="lower right")
plt.show()

"""*the model accuracy, precision and f1 score has improved from the previous model training*

predictive system:
"""

list1 = df.iloc[2:3, 0:9].values.flatten().tolist()
list1

ph = float(input('Enter the ph value = '))
Hardness = float(input('Enter the Hardness value = '))
Solids = float(input('Enter the Solids value = '))
Chloramines = float(input('Enter the Chloramines value = '))
Sulfate = float(input('Enter the Sulfate value = '))
Conductivity = float(input('Enter the Conductivity value = '))
Organic_carbon = float(input('Enter the Organic_carbon value = '))
Trihalomethanes = float(input('Enter the Trihalomethanes value = '))
Turbidity = float(input('Enter the Turbidity value = '))

input_data = [ph, Hardness, Solids, Chloramines, Sulfate, Conductivity, Organic_carbon, Trihalomethanes, Turbidity]

water_data_input = scaler.fit_transform([[ph, Hardness, Solids, Chloramines, Sulfate, Conductivity, Organic_carbon, Trihalomethanes, Turbidity]])
water_data_input   #scaling the input

#from the model evaluation above, ANN is the best model so far but i will consentrate on Random forest to build a model.
model_prediction = RF.predict(water_data_input)
model_prediction

if model_prediction[0] ==0:
  print('water is NOT SAFE for Consumption')
else:
  print('water is SAFE for Consumption')

def Water_Quality_Prediction(input_data):
   scaled_data = scaler.transform([input_data])
   model_prediction=RF.predict(scaled_data)
   if model_prediction [0] ==0:
      return "Water is 'NOT SAFE' for Consumption "
   else:
      return "Water is 'SAFE' for Consumption"

ph = float(input('Enter the ph value = '))
Hardness = float(input('Enter the Hardness value = '))
Solids = float(input('Enter the Solids value = '))
Chloramines = float(input('Enter the Chloramines value = '))
Sulfate = float(input('Enter the Sulfate value = '))
Conductivity = float(input('Enter the Conductivity value = '))
Organic_carbon = float(input('Enter the Organic_carbon value = '))
Trihalomethanes = float(input('Enter the Trihalomethanes value = '))
Turbidity = float(input('Enter the Turbidity value = '))

input_data = [ph, Hardness, Solids, Chloramines, Sulfate, Conductivity,
                                          Organic_carbon, Trihalomethanes, Turbidity]
Water_Quality_Prediction(input_data)